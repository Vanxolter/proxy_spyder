# Эта программа предназначена для автоматизированного сбора данных о прокси-серверах с веб-сайта https://belurk.online.
# Основные этапы работы программы:
# 1. Настройка и запуск Selenium WebDriver:
#    Программа использует Selenium для управления браузером. Драйвер настроен для работы в "headless" режиме, чтобы
#    скрыть окно браузера, а также для маскировки автоматизации.
# 2. Авторизация:
#    Программа использует учетные данные из файла .env (email и пароль) для входа на сайт.
# 3. Навигация и сбор данных:
#    Пользователь указывает желаемые типы прокси в списке WANTED_PROXYS, например, премиум или шэред прокси.
#    Из выбранных разделов извлекаются данные из таблиц, такие как IP-адреса и сроки действия.
# 4. Обработка данных:
#    BeautifulSoup анализирует HTML-код страницы, выбирая только указанные пользователем столбцы данных.
# 5. Вывод:
#    Результаты отображаются в консоли, где каждая строка представляет запись о прокси-сервере.
# Программа полезна для автоматизации процесса сбора и анализа информации о прокси-серверах.

from spyder.service import ProxySpyder

if __name__ == '__main__':
    process = ProxySpyder()
    process.run()
